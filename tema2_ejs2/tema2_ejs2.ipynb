{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 1:** Dado el texto siguiente, debemos tokenizarlo y:\n",
    "    - Mostrar cada token en una línea diferente.\n",
    "    - Añadir los diferentes tokens a una lista y mostrar la lista.\n",
    "    - Mostrar para cada token y en una línea diferente, el texto del token, la categoría gramatical y el lema.\n",
    "    - Contar el número de palabras vacías que se encuentran en el texto. Imprimir el número de palabras vacías y luego imprimir el número y las palabras vacías sin repeticiones.\n",
    "    - Mostrar los adjetivos que aparecen en el texto.\n",
    "    - Mostrar los nombres que aparecen en el texto. \n",
    "    - Mostrar para cada token su categoría gramatical y la explicación asociada a dicha categoría. Para ello se puede utilizar spacy.explain, que da una descripción acerca del tag particular del token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de ejemplo\n",
    "text = \"El 2025 viene cargado de innovaciones que repercutirán en nuestro modo de vida y de trabajo diario. Este año, las tendencias apuestan por los avances en inteligencia artificial (IA), automatización, conectividad y sostenibilidad. No sólo prometen una mayor eficiencia en el trabajo y una optimización de los procesos de decisión, sino también la superación de muchos de los retos actuales. Estas tendencias brindarán nuevas oportunidades tanto a empresas como a particulares. Echa un vistazo a las 5 tendencias tecnológicas más importantes, que marcarán el 2025.\"\n",
    "\n",
    "# Cargamos el modelo\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Mostrar cada token en una línea diferente ***\n",
      "El\n",
      "2025\n",
      "viene\n",
      "cargado\n",
      "de\n",
      "innovaciones\n",
      "que\n",
      "repercutirán\n",
      "en\n",
      "nuestro\n",
      "modo\n",
      "de\n",
      "vida\n",
      "y\n",
      "de\n",
      "trabajo\n",
      "diario\n",
      ".\n",
      "Este\n",
      "año\n",
      ",\n",
      "las\n",
      "tendencias\n",
      "apuestan\n",
      "por\n",
      "los\n",
      "avances\n",
      "en\n",
      "inteligencia\n",
      "artificial\n",
      "(\n",
      "IA\n",
      ")\n",
      ",\n",
      "automatización\n",
      ",\n",
      "conectividad\n",
      "y\n",
      "sostenibilidad\n",
      ".\n",
      "No\n",
      "sólo\n",
      "prometen\n",
      "una\n",
      "mayor\n",
      "eficiencia\n",
      "en\n",
      "el\n",
      "trabajo\n",
      "y\n",
      "una\n",
      "optimización\n",
      "de\n",
      "los\n",
      "procesos\n",
      "de\n",
      "decisión\n",
      ",\n",
      "sino\n",
      "también\n",
      "la\n",
      "superación\n",
      "de\n",
      "muchos\n",
      "de\n",
      "los\n",
      "retos\n",
      "actuales\n",
      ".\n",
      "Estas\n",
      "tendencias\n",
      "brindarán\n",
      "nuevas\n",
      "oportunidades\n",
      "tanto\n",
      "a\n",
      "empresas\n",
      "como\n",
      "a\n",
      "particulares\n",
      ".\n",
      "Echa\n",
      "un\n",
      "vistazo\n",
      "a\n",
      "las\n",
      "5\n",
      "tendencias\n",
      "tecnológicas\n",
      "más\n",
      "importantes\n",
      ",\n",
      "que\n",
      "marcarán\n",
      "el\n",
      "2025\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Mostrar cada token en una línea diferente ***\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Añadir los tokens a una lista y mostrarla ***\n",
      "['El', '2025', 'viene', 'cargado', 'de', 'innovaciones', 'que', 'repercutirán', 'en', 'nuestro', 'modo', 'de', 'vida', 'y', 'de', 'trabajo', 'diario', '.', 'Este', 'año', ',', 'las', 'tendencias', 'apuestan', 'por', 'los', 'avances', 'en', 'inteligencia', 'artificial', '(', 'IA', ')', ',', 'automatización', ',', 'conectividad', 'y', 'sostenibilidad', '.', 'No', 'sólo', 'prometen', 'una', 'mayor', 'eficiencia', 'en', 'el', 'trabajo', 'y', 'una', 'optimización', 'de', 'los', 'procesos', 'de', 'decisión', ',', 'sino', 'también', 'la', 'superación', 'de', 'muchos', 'de', 'los', 'retos', 'actuales', '.', 'Estas', 'tendencias', 'brindarán', 'nuevas', 'oportunidades', 'tanto', 'a', 'empresas', 'como', 'a', 'particulares', '.', 'Echa', 'un', 'vistazo', 'a', 'las', '5', 'tendencias', 'tecnológicas', 'más', 'importantes', ',', 'que', 'marcarán', 'el', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Añadir los tokens a una lista y mostrarla ***\")\n",
    "tokens = []\n",
    "for token in doc:\n",
    "    tokens.append(token.text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Mostrar cada token en una línea junto a su categoría gramatical y su lema ***\n",
      "Token: El; Categ. gramatical: DET; Lema: el\n",
      "Token: 2025; Categ. gramatical: NOUN; Lema: 2025\n",
      "Token: viene; Categ. gramatical: VERB; Lema: venir\n",
      "Token: cargado; Categ. gramatical: ADJ; Lema: cargado\n",
      "Token: de; Categ. gramatical: ADP; Lema: de\n",
      "Token: innovaciones; Categ. gramatical: NOUN; Lema: innovación\n",
      "Token: que; Categ. gramatical: PRON; Lema: que\n",
      "Token: repercutirán; Categ. gramatical: VERB; Lema: repercutir\n",
      "Token: en; Categ. gramatical: ADP; Lema: en\n",
      "Token: nuestro; Categ. gramatical: DET; Lema: nuestro\n",
      "Token: modo; Categ. gramatical: NOUN; Lema: modo\n",
      "Token: de; Categ. gramatical: ADP; Lema: de\n",
      "Token: vida; Categ. gramatical: NOUN; Lema: vida\n",
      "Token: y; Categ. gramatical: CCONJ; Lema: y\n",
      "Token: de; Categ. gramatical: ADP; Lema: de\n",
      "Token: trabajo; Categ. gramatical: NOUN; Lema: trabajo\n",
      "Token: diario; Categ. gramatical: ADJ; Lema: diario\n",
      "Token: .; Categ. gramatical: PUNCT; Lema: .\n",
      "Token: Este; Categ. gramatical: DET; Lema: este\n",
      "Token: año; Categ. gramatical: NOUN; Lema: año\n",
      "Token: ,; Categ. gramatical: PUNCT; Lema: ,\n",
      "Token: las; Categ. gramatical: DET; Lema: el\n",
      "Token: tendencias; Categ. gramatical: NOUN; Lema: tendencia\n",
      "Token: apuestan; Categ. gramatical: VERB; Lema: apostar\n",
      "Token: por; Categ. gramatical: ADP; Lema: por\n",
      "Token: los; Categ. gramatical: DET; Lema: el\n",
      "Token: avances; Categ. gramatical: NOUN; Lema: avance\n",
      "Token: en; Categ. gramatical: ADP; Lema: en\n",
      "Token: inteligencia; Categ. gramatical: NOUN; Lema: inteligencia\n",
      "Token: artificial; Categ. gramatical: ADJ; Lema: artificial\n",
      "Token: (; Categ. gramatical: PUNCT; Lema: (\n",
      "Token: IA; Categ. gramatical: PROPN; Lema: IA\n",
      "Token: ); Categ. gramatical: PUNCT; Lema: )\n",
      "Token: ,; Categ. gramatical: PUNCT; Lema: ,\n",
      "Token: automatización; Categ. gramatical: NOUN; Lema: automatización\n",
      "Token: ,; Categ. gramatical: PUNCT; Lema: ,\n",
      "Token: conectividad; Categ. gramatical: NOUN; Lema: conectividad\n",
      "Token: y; Categ. gramatical: CCONJ; Lema: y\n",
      "Token: sostenibilidad; Categ. gramatical: NOUN; Lema: sostenibilidad\n",
      "Token: .; Categ. gramatical: PUNCT; Lema: .\n",
      "Token: No; Categ. gramatical: PART; Lema: no\n",
      "Token: sólo; Categ. gramatical: ADV; Lema: sólo\n",
      "Token: prometen; Categ. gramatical: VERB; Lema: prometer\n",
      "Token: una; Categ. gramatical: DET; Lema: uno\n",
      "Token: mayor; Categ. gramatical: ADJ; Lema: mayor\n",
      "Token: eficiencia; Categ. gramatical: NOUN; Lema: eficiencia\n",
      "Token: en; Categ. gramatical: ADP; Lema: en\n",
      "Token: el; Categ. gramatical: DET; Lema: el\n",
      "Token: trabajo; Categ. gramatical: NOUN; Lema: trabajo\n",
      "Token: y; Categ. gramatical: CCONJ; Lema: y\n",
      "Token: una; Categ. gramatical: DET; Lema: uno\n",
      "Token: optimización; Categ. gramatical: NOUN; Lema: optimización\n",
      "Token: de; Categ. gramatical: ADP; Lema: de\n",
      "Token: los; Categ. gramatical: DET; Lema: el\n",
      "Token: procesos; Categ. gramatical: NOUN; Lema: proceso\n",
      "Token: de; Categ. gramatical: ADP; Lema: de\n",
      "Token: decisión; Categ. gramatical: NOUN; Lema: decisión\n",
      "Token: ,; Categ. gramatical: PUNCT; Lema: ,\n",
      "Token: sino; Categ. gramatical: CCONJ; Lema: sino\n",
      "Token: también; Categ. gramatical: NOUN; Lema: también\n",
      "Token: la; Categ. gramatical: DET; Lema: el\n",
      "Token: superación; Categ. gramatical: NOUN; Lema: superación\n",
      "Token: de; Categ. gramatical: ADP; Lema: de\n",
      "Token: muchos; Categ. gramatical: PRON; Lema: mucho\n",
      "Token: de; Categ. gramatical: ADP; Lema: de\n",
      "Token: los; Categ. gramatical: DET; Lema: el\n",
      "Token: retos; Categ. gramatical: NOUN; Lema: reto\n",
      "Token: actuales; Categ. gramatical: ADJ; Lema: actual\n",
      "Token: .; Categ. gramatical: PUNCT; Lema: .\n",
      "Token: Estas; Categ. gramatical: DET; Lema: este\n",
      "Token: tendencias; Categ. gramatical: NOUN; Lema: tendencia\n",
      "Token: brindarán; Categ. gramatical: VERB; Lema: brindar\n",
      "Token: nuevas; Categ. gramatical: ADJ; Lema: nuevo\n",
      "Token: oportunidades; Categ. gramatical: NOUN; Lema: oportunidad\n",
      "Token: tanto; Categ. gramatical: ADV; Lema: tanto\n",
      "Token: a; Categ. gramatical: ADP; Lema: a\n",
      "Token: empresas; Categ. gramatical: NOUN; Lema: empresa\n",
      "Token: como; Categ. gramatical: SCONJ; Lema: como\n",
      "Token: a; Categ. gramatical: ADP; Lema: a\n",
      "Token: particulares; Categ. gramatical: NOUN; Lema: particular\n",
      "Token: .; Categ. gramatical: PUNCT; Lema: .\n",
      "Token: Echa; Categ. gramatical: VERB; Lema: echar\n",
      "Token: un; Categ. gramatical: DET; Lema: uno\n",
      "Token: vistazo; Categ. gramatical: NOUN; Lema: vistazo\n",
      "Token: a; Categ. gramatical: ADP; Lema: a\n",
      "Token: las; Categ. gramatical: DET; Lema: el\n",
      "Token: 5; Categ. gramatical: NUM; Lema: 5\n",
      "Token: tendencias; Categ. gramatical: NOUN; Lema: tendencia\n",
      "Token: tecnológicas; Categ. gramatical: ADJ; Lema: tecnológico\n",
      "Token: más; Categ. gramatical: ADV; Lema: más\n",
      "Token: importantes; Categ. gramatical: ADJ; Lema: importante\n",
      "Token: ,; Categ. gramatical: PUNCT; Lema: ,\n",
      "Token: que; Categ. gramatical: PRON; Lema: que\n",
      "Token: marcarán; Categ. gramatical: VERB; Lema: marcar\n",
      "Token: el; Categ. gramatical: DET; Lema: el\n",
      "Token: 2025; Categ. gramatical: NOUN; Lema: 2025\n",
      "Token: .; Categ. gramatical: PUNCT; Lema: .\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Mostrar cada token en una línea junto a su categoría gramatical y su lema ***\")\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}; Categ. gramatical: {token.tag_}; Lema: {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Número de palabras vacías ***\n",
      "45\n",
      "Sin repeticiones: 27\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Número de palabras vacías ***\")\n",
    "stopwords = []\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        stopwords.append(token.text)\n",
    "print(len(stopwords))\n",
    "print(f\"Sin repeticiones: {len(set(stopwords))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Adjetivos del texto ***\n",
      "cargado\n",
      "diario\n",
      "artificial\n",
      "mayor\n",
      "actuales\n",
      "nuevas\n",
      "tecnológicas\n",
      "importantes\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Adjetivos del texto ***\")\n",
    "for token in doc:\n",
    "    if token.tag_ == \"ADJ\":\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Nombres del texto ***\n",
      "2025\n",
      "innovaciones\n",
      "modo\n",
      "vida\n",
      "trabajo\n",
      "año\n",
      "tendencias\n",
      "avances\n",
      "inteligencia\n",
      "automatización\n",
      "conectividad\n",
      "sostenibilidad\n",
      "eficiencia\n",
      "trabajo\n",
      "optimización\n",
      "procesos\n",
      "decisión\n",
      "también\n",
      "superación\n",
      "retos\n",
      "tendencias\n",
      "oportunidades\n",
      "empresas\n",
      "particulares\n",
      "vistazo\n",
      "tendencias\n",
      "2025\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Nombres del texto ***\")\n",
    "for token in doc:\n",
    "    if token.tag_ == \"NOUN\":\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Mostrar la categ. gramatical de cada token junto a su explicación ***\n",
      "Token: El;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: 2025;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: viene;\n",
      "Categ. gramatical: VERB;\n",
      "Explicación: verb\n",
      "\n",
      "Token: cargado;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: de;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: innovaciones;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: que;\n",
      "Categ. gramatical: PRON;\n",
      "Explicación: pronoun\n",
      "\n",
      "Token: repercutirán;\n",
      "Categ. gramatical: VERB;\n",
      "Explicación: verb\n",
      "\n",
      "Token: en;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: nuestro;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: modo;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: de;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: vida;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: y;\n",
      "Categ. gramatical: CCONJ;\n",
      "Explicación: coordinating conjunction\n",
      "\n",
      "Token: de;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: trabajo;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: diario;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: .;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: Este;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: año;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: ,;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: las;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: tendencias;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: apuestan;\n",
      "Categ. gramatical: VERB;\n",
      "Explicación: verb\n",
      "\n",
      "Token: por;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: los;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: avances;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: en;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: inteligencia;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: artificial;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: (;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: IA;\n",
      "Categ. gramatical: PROPN;\n",
      "Explicación: proper noun\n",
      "\n",
      "Token: );\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: ,;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: automatización;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: ,;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: conectividad;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: y;\n",
      "Categ. gramatical: CCONJ;\n",
      "Explicación: coordinating conjunction\n",
      "\n",
      "Token: sostenibilidad;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: .;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: No;\n",
      "Categ. gramatical: PART;\n",
      "Explicación: particle\n",
      "\n",
      "Token: sólo;\n",
      "Categ. gramatical: ADV;\n",
      "Explicación: adverb\n",
      "\n",
      "Token: prometen;\n",
      "Categ. gramatical: VERB;\n",
      "Explicación: verb\n",
      "\n",
      "Token: una;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: mayor;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: eficiencia;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: en;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: el;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: trabajo;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: y;\n",
      "Categ. gramatical: CCONJ;\n",
      "Explicación: coordinating conjunction\n",
      "\n",
      "Token: una;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: optimización;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: de;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: los;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: procesos;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: de;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: decisión;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: ,;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: sino;\n",
      "Categ. gramatical: CCONJ;\n",
      "Explicación: coordinating conjunction\n",
      "\n",
      "Token: también;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: la;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: superación;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: de;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: muchos;\n",
      "Categ. gramatical: PRON;\n",
      "Explicación: pronoun\n",
      "\n",
      "Token: de;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: los;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: retos;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: actuales;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: .;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: Estas;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: tendencias;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: brindarán;\n",
      "Categ. gramatical: VERB;\n",
      "Explicación: verb\n",
      "\n",
      "Token: nuevas;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: oportunidades;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: tanto;\n",
      "Categ. gramatical: ADV;\n",
      "Explicación: adverb\n",
      "\n",
      "Token: a;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: empresas;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: como;\n",
      "Categ. gramatical: SCONJ;\n",
      "Explicación: subordinating conjunction\n",
      "\n",
      "Token: a;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: particulares;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: .;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: Echa;\n",
      "Categ. gramatical: VERB;\n",
      "Explicación: verb\n",
      "\n",
      "Token: un;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: vistazo;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: a;\n",
      "Categ. gramatical: ADP;\n",
      "Explicación: adposition\n",
      "\n",
      "Token: las;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: 5;\n",
      "Categ. gramatical: NUM;\n",
      "Explicación: numeral\n",
      "\n",
      "Token: tendencias;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: tecnológicas;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: más;\n",
      "Categ. gramatical: ADV;\n",
      "Explicación: adverb\n",
      "\n",
      "Token: importantes;\n",
      "Categ. gramatical: ADJ;\n",
      "Explicación: adjective\n",
      "\n",
      "Token: ,;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n",
      "Token: que;\n",
      "Categ. gramatical: PRON;\n",
      "Explicación: pronoun\n",
      "\n",
      "Token: marcarán;\n",
      "Categ. gramatical: VERB;\n",
      "Explicación: verb\n",
      "\n",
      "Token: el;\n",
      "Categ. gramatical: DET;\n",
      "Explicación: determiner\n",
      "\n",
      "Token: 2025;\n",
      "Categ. gramatical: NOUN;\n",
      "Explicación: noun\n",
      "\n",
      "Token: .;\n",
      "Categ. gramatical: PUNCT;\n",
      "Explicación: punctuation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Mostrar la categ. gramatical de cada token junto a su explicación ***\")\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text};\\nCateg. gramatical: {token.tag_};\\nExplicación: {spacy.explain(token.tag_)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 2:** dado el mismo texto en español del ejercicio anterior, se pide lo siguiente:\n",
    "    - Imprimir el número de oraciones que hay en el párrafo e imprimir cada una de ellas.\n",
    "    - Para cada oración, eliminar las palabras vacías y formar la oración de nuevo sin ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Imprimir oraciones y núm. oraciones ***\n",
      "El 2025 viene cargado de innovaciones que repercutirán en nuestro modo de vida y de trabajo diario.\n",
      "Este año, las tendencias apuestan por los avances en inteligencia artificial (IA), automatización, conectividad y sostenibilidad.\n",
      "No sólo prometen una mayor eficiencia en el trabajo y una optimización de los procesos de decisión, sino también la superación de muchos de los retos actuales.\n",
      "Estas tendencias brindarán nuevas oportunidades tanto a empresas como a particulares.\n",
      "Echa un vistazo a las 5 tendencias tecnológicas más importantes, que marcarán el 2025.\n",
      "Número de oraciones: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Imprimir oraciones y núm. oraciones ***\")\n",
    "num_sents = 0\n",
    "for sent in doc.sents:\n",
    "    num_sents += 1\n",
    "    print(sent)\n",
    "print(f\"Número de oraciones: {num_sents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Eliminar palabras vacías de cada oración ***\n",
      "[[2025, viene, cargado, innovaciones, repercutirán, vida, trabajo, diario, .], [año, ,, tendencias, apuestan, avances, inteligencia, artificial, (, IA, ), ,, automatización, ,, conectividad, sostenibilidad, .], [prometen, eficiencia, trabajo, optimización, procesos, decisión, ,, superación, retos, actuales, .], [tendencias, brindarán, oportunidades, empresas, particulares, .], [Echa, vistazo, 5, tendencias, tecnológicas, importantes, ,, marcarán, 2025, .]]\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Eliminar palabras vacías de cada oración ***\")\n",
    "sents_without_sw = []\n",
    "for sent in doc.sents:\n",
    "    sents_without_sw.append([token for token in sent if not token.is_stop])\n",
    "print(sents_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 3:** Dado el mismo texto en español de los ejercicios anteriores se quieren calcular estadísticas sobre frecuencias de las palabras del texto. Para ello, primero eliminar las palabras vacías y los signos de puntuación y sobre el listado de palabras resultante se pide:\n",
    "    - Obtener la frecuencia de cada palabra, imprimiendo el par palabra-frecuencia.\n",
    "    - Mostrar sólo aquellas palabras cuya frecuencia sea mayor que 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for token in doc:\n",
    "    tokens.append(token) if (not token.is_stop and not token.is_punct) else None\n",
    "freq_keys = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2025,\n",
       " viene,\n",
       " cargado,\n",
       " innovaciones,\n",
       " repercutirán,\n",
       " vida,\n",
       " trabajo,\n",
       " diario,\n",
       " año,\n",
       " tendencias,\n",
       " apuestan,\n",
       " avances,\n",
       " inteligencia,\n",
       " artificial,\n",
       " IA,\n",
       " automatización,\n",
       " conectividad,\n",
       " sostenibilidad,\n",
       " prometen,\n",
       " eficiencia,\n",
       " trabajo,\n",
       " optimización,\n",
       " procesos,\n",
       " decisión,\n",
       " superación,\n",
       " retos,\n",
       " actuales,\n",
       " tendencias,\n",
       " brindarán,\n",
       " oportunidades,\n",
       " empresas,\n",
       " particulares,\n",
       " Echa,\n",
       " vistazo,\n",
       " 5,\n",
       " tendencias,\n",
       " tecnológicas,\n",
       " importantes,\n",
       " marcarán,\n",
       " 2025}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
