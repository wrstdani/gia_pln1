{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from pywsd import adapted_lesk\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_sw = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 1:** Se quiere desarrollar un evaluador de sentimientos basado en el uso de un recursos ling眉铆stico externo, en concreto, las listas de palabras de opini贸n que tiene NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion1 = \"Visceral, stunning and relentless film making. Dicaprio's Herculean, almost purely physical performance\" \\\n",
    "            \"and Hardy's wide eyed intensity coupled with the almost overwhelming beauty of the landscape - those \" \\\n",
    "            \"trees, the natural light, the sun peeking through the clouds, rendered the proceedings down to savage\" \\\n",
    "            \"poetry. A hypnotic, beautiful, exhausting film.\"\n",
    "\n",
    "opinion2 = \"I saw this film on Friday. For the first 40 minutes involving spoken dialogue they need not have \" \\\n",
    "            \"bothered. For me the dialogue was totally unintelligible with grunting, southern states drawl, \" \\\n",
    "            \"and coarse accent that made it impossible to understand what they were saying.\"\n",
    "\n",
    "opinion3 = \"It was a idiotic film that produces a magnificent fascination.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "    word_tokenized = [word_tokenize(s) for s in sent_tokenized]\n",
    "    return word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            if w in opinion_lexicon.positive() and w in opinion_lexicon.negative():\n",
    "                score += 0\n",
    "            elif w in opinion_lexicon.positive():\n",
    "                score += 1\n",
    "            elif w in opinion_lexicon.negative():\n",
    "                score -= 1\n",
    "    if score == 0:\n",
    "        return \"neutro\", score\n",
    "    elif score > 0:\n",
    "        return \"pos\", score\n",
    "    else:\n",
    "        return \"neg\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 1\n",
    "print(classify(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', -4)\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 2\n",
    "print(classify(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 3\n",
    "print(classify(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 2:** Se pide lo mismo que en el ejercicio anterior, pero en este caso utilizando SentiWordNet (disponible en NLTK). Esta base de datos proporciona valores positivos y negativos para ciertas palabras en un rango entre -1 y 1. Se puede seguir la misma idea de algoritmo que en el caso anterior, pero hay que tener en cuenta que SentiWordNet nos proporciona puntuaciones para los diferentes sentidos que tiene una palabra. Se puede entonces considerar la puntuaci贸n de todos los sentidos de la misma palabra, restando a lo positivo la puntuaci贸n negativa. Puede ser interesante que la puntuaci贸n global se promedie de acuerdo con el n煤mero de sentidos.  Utilizar como entrada las mismas opiniones del ejercicio anterior. 驴El resultado es mejor o peor que el conseguido con el algoritmo del ejercicio 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_swn(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    total_score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            synsets = list(swn.senti_synsets(w))\n",
    "            word_score = 0\n",
    "            for synset in synsets:\n",
    "                word_score += (synset.pos_score() - synset.neg_score())\n",
    "            if len(synsets) > 0:\n",
    "                total_score += word_score / len(synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4219623904464331\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 1\n",
    "print(classify_swn(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.25598923992673994\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 2\n",
    "print(classify_swn(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7648809523809523\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 3\n",
    "print(classify_swn(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 2.1:** Hacer una variante del ejercicio donde se tengan en cuenta primero la categor铆a gramatical del token para considerar 煤nicamente los scores de los sentidos que coincidan con la categor铆a gramatical dada. 驴Ha mejorado el resultado o ha empeorado con respecto a versiones anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n auxiliar para convertir un\n",
    "# tag generado por nltk.pos_tag()\n",
    "# en una categ. gramatical de \n",
    "# WordNet\n",
    "def tag2wn(tag):\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wn.VERB\n",
    "    elif tag.startswith(\"J\"):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def classify_swn_gram(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    tags = [nltk.pos_tag(s) for s in word_tokenized]\n",
    "    total_score = 0\n",
    "    for s in tags:\n",
    "        for w, t in s:\n",
    "            synsets = list(swn.senti_synsets(w, tag2wn(t)))\n",
    "            word_score = 0\n",
    "            for synset in synsets:\n",
    "                word_score += (synset.pos_score() - synset.neg_score())\n",
    "            if len(synsets) > 0:\n",
    "                total_score += word_score / len(synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5139880952380951\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 1\n",
    "print(classify_swn_gram(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05469148771028469\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 2\n",
    "print(classify_swn_gram(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655677655677655\n"
     ]
    }
   ],
   "source": [
    "# Opini贸n 3\n",
    "print(classify_swn_gram(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que la mejora es m谩s bien leve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 3:** Se pide extender lo que se ha hecho en los ejercicios anteriores, pero ampliado para todas las opiniones contenidas en un fichero .csv (textsSentimentsPNN.csv), donde cada opini贸n est谩 anotada con su polaridad (positiva, negativa o neutra). Un ejemplo del formato del archivo se muestra a continuaci贸n, en la primera columna estar铆a el texto de la opini贸n y en la segunda el sentimiento (Positive, Negative o Neutral).  \n",
    " \n",
    "    Utilizando de nuevo SentiWordNet se pide predecir la polaridad de cada mensaje. Una vez que se tenga la polaridad de cada mensaje, utilizar las m茅tricas del paquete sklearn.metrics de la librer铆a scikit-learn para obtener los valores de accuracy, precisi贸n, recall y f-measure. En definitiva, se quiere poder cuantificar si se est谩n clasificando bien las opiniones seg煤n su polaridad. Cuanto m谩s cercano a 1 sea el valor que se obtiene con estas m茅tricas, mejor estar谩 clasificando cada mensaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! </td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!  Positive\n",
       "1           Traffic was terrible this morning.  Negative\n",
       "2          Just finished an amazing workout!   Positive\n",
       "3  Excited about the upcoming weekend getaway!  Positive\n",
       "4  Trying out a new recipe for dinner tonight.   Neutral"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentiments = pd.read_csv(\"data/textsSentimentsPNN.csv\")\n",
    "text_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! </td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!         1\n",
       "1           Traffic was terrible this morning.         2\n",
       "2          Just finished an amazing workout!          1\n",
       "3  Excited about the upcoming weekend getaway!         1\n",
       "4  Trying out a new recipe for dinner tonight.         0"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sustituimos:\n",
    "# Positive -> 1\n",
    "# Neutral -> 0\n",
    "# Negative -> 2\n",
    "positive = text_sentiments[\"Sentiment\"] == \"Positive\"\n",
    "neutral = text_sentiments[\"Sentiment\"] == \"Neutral\"\n",
    "negative = text_sentiments[\"Sentiment\"] == \"Negative\"\n",
    "\n",
    "text_sentiments.loc[positive, \"Sentiment\"] = 1\n",
    "text_sentiments.loc[neutral, \"Sentiment\"] = 0\n",
    "text_sentiments.loc[negative, \"Sentiment\"] = 2\n",
    "\n",
    "text_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n auxiliar para tokenizar el texto\n",
    "def preprocess_text(text):\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "    word_tokenized_no_punct = [regexp_tokenize(s, r\"[\\w\\d]+\") for s in sent_tokenized]\n",
    "    # Eliminamos puntuaci贸n y stopwords\n",
    "    no_punct_no_sw = []\n",
    "    for s in word_tokenized_no_punct:\n",
    "        no_punct_no_sw.append([w for w in s if w not in english_sw])\n",
    "\n",
    "    tagged = [nltk.pos_tag(s) for s in no_punct_no_sw]\n",
    "\n",
    "    return tagged\n",
    "\n",
    "# Clasificamos cada texto aplicando WSD previamente\n",
    "def classify_text(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    total_score = 0\n",
    "    for s in preprocessed_text:\n",
    "        sent_score = 0\n",
    "        for w, t in s:\n",
    "            senti_synsets = swn.senti_synsets(w, tag2wn(t))\n",
    "            for senti_synset in senti_synsets:\n",
    "                if senti_synset is not None:\n",
    "                    sent_score += (senti_synset.pos_score() - senti_synset.neg_score())\n",
    "        total_score += sent_score\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos y normalizamos las predicciones\n",
    "sentiments_pred = [classify_text(text) for text in text_sentiments[\"Text\"]]\n",
    "min_pred = min(sentiments_pred)\n",
    "max_pred = max(sentiments_pred)\n",
    "\n",
    "normalized_pred = [2 * ((pred - min_pred) / (max_pred - min_pred)) - 1 for pred in sentiments_pred]\n",
    "normalized_pred = np.array(normalized_pred).astype(np.float32)\n",
    "\n",
    "threshold = 0.1\n",
    "positive_pred = normalized_pred > threshold\n",
    "negative_pred = normalized_pred < -threshold\n",
    "neutral_pred = (normalized_pred >= -threshold) & (normalized_pred <= threshold)\n",
    "y_pred = normalized_pred.copy()\n",
    "y_pred[positive_pred] = 1\n",
    "y_pred[neutral_pred] = 0\n",
    "y_pred[negative_pred] = 2\n",
    "y_pred = y_pred.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1044776119402985\n",
      "Precision: 0.6753731343283582\n",
      "Recall: 0.1044776119402985\n",
      "F-score: 0.09097892888498683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wrst/miniconda3/envs/pln1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(text_sentiments[\"Sentiment\"], dtype=np.uint8)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred, average=\"weighted\")}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred, average=\"weighted\")}\")\n",
    "print(f\"F-score: {f1_score(y_true, y_pred, average=\"weighted\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1 0 1 1 1 2 0 1 2 1 1 0 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.    -2.625  0.25   0.5    0.5   -1.     2.25   1.375  0.125 -0.375\n",
      "  1.25   0.125  0.875  1.75   2.375  1.875  2.125 -0.125  0.25  -3.375\n",
      " 15.     0.875  2.375  0.875  0.5    0.375  0.625 12.125  2.625  0.125\n",
      " -1.5    3.     1.     0.375  0.     2.75   3.     0.625  0.5    0.\n",
      "  0.5    0.75   3.5   12.75   0.75   0.625  0.75   3.25   2.625  1.375\n",
      "  1.625 -0.125 -0.125  1.75   4.     1.25   0.625  2.875  0.375  1.875\n",
      "  0.    -0.125  2.25   1.375  1.875  1.625  3.   ]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
