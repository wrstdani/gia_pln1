{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from pywsd import simple_lesk\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_sw = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 1:** Se quiere desarrollar un evaluador de sentimientos basado en el uso de un recursos lingüístico externo, en concreto, las listas de palabras de opinión que tiene NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion1 = \"Visceral, stunning and relentless film making. Dicaprio's Herculean, almost purely physical performance\" \\\n",
    "            \"and Hardy's wide eyed intensity coupled with the almost overwhelming beauty of the landscape - those \" \\\n",
    "            \"trees, the natural light, the sun peeking through the clouds, rendered the proceedings down to savage\" \\\n",
    "            \"poetry. A hypnotic, beautiful, exhausting film.\"\n",
    "\n",
    "opinion2 = \"I saw this film on Friday. For the first 40 minutes involving spoken dialogue they need not have \" \\\n",
    "            \"bothered. For me the dialogue was totally unintelligible with grunting, southern states drawl, \" \\\n",
    "            \"and coarse accent that made it impossible to understand what they were saying.\"\n",
    "\n",
    "opinion3 = \"It was a idiotic film that produces a magnificent fascination.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "    word_tokenized = [word_tokenize(s) for s in sent_tokenized]\n",
    "    return word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            if w in opinion_lexicon.positive() and w in opinion_lexicon.negative():\n",
    "                score += 0\n",
    "            elif w in opinion_lexicon.positive():\n",
    "                score += 1\n",
    "            elif w in opinion_lexicon.negative():\n",
    "                score -= 1\n",
    "    if score == 0:\n",
    "        return \"neutro\", score\n",
    "    elif score > 0:\n",
    "        return \"pos\", score\n",
    "    else:\n",
    "        return \"neg\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opinión 1\n",
    "print(classify(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', -4)\n"
     ]
    }
   ],
   "source": [
    "# Opinión 2\n",
    "print(classify(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opinión 3\n",
    "print(classify(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 2:** Se pide lo mismo que en el ejercicio anterior, pero en este caso utilizando SentiWordNet (disponible en NLTK). Esta base de datos proporciona valores positivos y negativos para ciertas palabras en un rango entre -1 y 1. Se puede seguir la misma idea de algoritmo que en el caso anterior, pero hay que tener en cuenta que SentiWordNet nos proporciona puntuaciones para los diferentes sentidos que tiene una palabra. Se puede entonces considerar la puntuación de todos los sentidos de la misma palabra, restando a lo positivo la puntuación negativa. Puede ser interesante que la puntuación global se promedie de acuerdo con el número de sentidos.  Utilizar como entrada las mismas opiniones del ejercicio anterior. ¿El resultado es mejor o peor que el conseguido con el algoritmo del ejercicio 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_swn(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    total_score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            senti_synsets = list(swn.senti_synsets(w))\n",
    "            word_score = 0\n",
    "            for senti_synset in senti_synsets:\n",
    "                word_score += senti_synset.obj_score()\n",
    "            if len(senti_synsets) > 0:\n",
    "                total_score += word_score / len(senti_synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.784353633954698\n"
     ]
    }
   ],
   "source": [
    "# Opinión 1\n",
    "print(classify_swn(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.681840555278054\n"
     ]
    }
   ],
   "source": [
    "# Opinión 2\n",
    "print(classify_swn(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.056547619047619\n"
     ]
    }
   ],
   "source": [
    "# Opinión 3\n",
    "print(classify_swn(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 2.1:** Hacer una variante del ejercicio donde se tengan en cuenta primero la categoría gramatical del token para considerar únicamente los scores de los sentidos que coincidan con la categoría gramatical dada. ¿Ha mejorado el resultado o ha empeorado con respecto a versiones anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para convertir un\n",
    "# tag generado por nltk.pos_tag()\n",
    "# en una categ. gramatical de \n",
    "# WordNet\n",
    "def tag2wn(tag):\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wn.VERB\n",
    "    elif tag.startswith(\"J\"):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def classify_swn_gram(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    tags = [nltk.pos_tag(s) for s in word_tokenized]\n",
    "    total_score = 0\n",
    "    for s in tags:\n",
    "        for w, t in s:\n",
    "            synsets = list(swn.senti_synsets(w, tag2wn(t)))\n",
    "            word_score = 0\n",
    "            for synset in synsets:\n",
    "                word_score += synset.obj_score()\n",
    "            if len(synsets) > 0:\n",
    "                total_score += word_score / len(synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.805654761904766\n"
     ]
    }
   ],
   "source": [
    "# Opinión 1\n",
    "print(classify_swn_gram(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.569603892348248\n"
     ]
    }
   ],
   "source": [
    "# Opinión 2\n",
    "print(classify_swn_gram(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.053113553113552\n"
     ]
    }
   ],
   "source": [
    "# Opinión 3\n",
    "print(classify_swn_gram(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que la mejora es más bien leve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 3:** Se pide extender lo que se ha hecho en los ejercicios anteriores, pero ampliado para todas las opiniones contenidas en un fichero .csv (textsSentimentsPNN.csv), donde cada opinión está anotada con su polaridad (positiva, negativa o neutra). Un ejemplo del formato del archivo se muestra a continuación, en la primera columna estaría el texto de la opinión y en la segunda el sentimiento (Positive, Negative o Neutral).  \n",
    " \n",
    "    Utilizando de nuevo SentiWordNet se pide predecir la polaridad de cada mensaje. Una vez que se tenga la polaridad de cada mensaje, utilizar las métricas del paquete sklearn.metrics de la librería scikit-learn para obtener los valores de accuracy, precisión, recall y f-measure. En definitiva, se quiere poder cuantificar si se están clasificando bien las opiniones según su polaridad. Cuanto más cercano a 1 sea el valor que se obtiene con estas métricas, mejor estará clasificando cada mensaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! 💪</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!  Positive\n",
       "1           Traffic was terrible this morning.  Negative\n",
       "2          Just finished an amazing workout! 💪  Positive\n",
       "3  Excited about the upcoming weekend getaway!  Positive\n",
       "4  Trying out a new recipe for dinner tonight.   Neutral"
      ]
     },
     "execution_count": 1304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos el archivo \".csv\" con pandas\n",
    "texts_sentiments = pd.read_csv(\"data/textsSentimentsPNN.csv\")\n",
    "\n",
    "# Mostramos las 5 primeras filas\n",
    "texts_sentiments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1     False\n",
       "2      True\n",
       "3      True\n",
       "4     False\n",
       "      ...  \n",
       "62    False\n",
       "63    False\n",
       "64    False\n",
       "65    False\n",
       "66    False\n",
       "Name: Sentiment, Length: 67, dtype: bool"
      ]
     },
     "execution_count": 1305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_sentiments[\"Sentiment\"] == \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! 💪</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!         1\n",
       "1           Traffic was terrible this morning.         2\n",
       "2          Just finished an amazing workout! 💪         1\n",
       "3  Excited about the upcoming weekend getaway!         1\n",
       "4  Trying out a new recipe for dinner tonight.         0"
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un diccionario para codificar las etiquetas\n",
    "dicc_encode = {\n",
    "    \"Neutral\": 0,\n",
    "    \"Positive\": 1,\n",
    "    \"Negative\": 2\n",
    "}\n",
    "\n",
    "# Aplicamos la transformación y comprobamos el resultado\n",
    "for key, value in dicc_encode.items():\n",
    "    mask = (texts_sentiments[\"Sentiment\"] == key)\n",
    "    texts_sentiments.loc[mask, \"Sentiment\"] = value\n",
    "\n",
    "texts_sentiments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Enjoying a beautiful day at the park!\n",
      "Texto preprocesado: (['Enjoying a beautiful day at the park!'], [['Enjoying', 'beautiful', 'day', 'park']])\n"
     ]
    }
   ],
   "source": [
    "# Función para preprocesar cada texto\n",
    "def preprocess_text(text):\n",
    "    # Tokenizamos el texto en sentencias\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "\n",
    "    # Tokenizamos cada sentencia en palabras,\n",
    "    # eliminando a su vez la puntuación\n",
    "    word_tokenized_np = [regexp_tokenize(s.lower(), r\"[\\w\\d]+\") for s in sent_tokenized]\n",
    "\n",
    "    # Eliminamos las stopwords\n",
    "    word_tokenized_np_nsw = []\n",
    "    for s in word_tokenized_np:\n",
    "        word_tokenized_np_nsw.append([w for w in s if w not in english_sw])\n",
    "    \n",
    "    # Lematizamos\n",
    "    lemmatized_tokens = []\n",
    "    for s in word_tokenized_np_nsw:\n",
    "        lemmatized_tokens.append([WordNetLemmatizer().lemmatize(w) for w in s])\n",
    "\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Mostramos un ejemplo de cómo quedaría un texto preprocesado\n",
    "print(f\"Texto original: {texts_sentiments[\"Text\"][0]}\")\n",
    "print(f\"Texto preprocesado: {preprocess_text(texts_sentiments[\"Text\"][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Enjoying a beautiful day at the park!\n",
      "Score: 0.023986486486486484\n"
     ]
    }
   ],
   "source": [
    "# Función para obtener el score de un texto\n",
    "def get_text_score(text):\n",
    "    preprocessed = preprocess_text(text)\n",
    "    tags = [nltk.pos_tag(s) for s in preprocessed]\n",
    "    total_score = 0\n",
    "    for s_idx in range(len(preprocessed)):\n",
    "        sent_score = 0\n",
    "        for w, t in tags[s_idx]:\n",
    "            synset = simple_lesk(\" \".join(preprocessed[s_idx]), w, tag2wn(t))\n",
    "            if synset is not None:\n",
    "                \n",
    "\n",
    "# Mostramos un ejemplo de score para un texto\n",
    "print(f\"Texto: {texts_sentiments[\"Text\"][0]}\")\n",
    "print(f\"Score: {get_text_score(texts_sentiments[\"Text\"][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02398649 0.         0.         0.         0.         0.\n",
      " 0.00124008 0.00411184 0.         0.         0.         0.\n",
      " 0.         0.00558036 0.00145688 0.         0.0094697  0.\n",
      " 0.         0.         0.01779762 0.         0.01143293 0.\n",
      " 0.         0.         0.         0.01651306 0.01358696 0.\n",
      " 0.         0.00434783 0.         0.         0.         0.00526316\n",
      " 0.00594406 0.         0.         0.         0.         0.\n",
      " 0.01633523 0.01551227 0.         0.         0.         0.\n",
      " 0.01015625 0.0078125  0.00372024 0.         0.00173611 0.003125\n",
      " 0.00238715 0.         0.         0.00102041 0.         0.00107143\n",
      " 0.         0.00138889 0.00214844 0.0010274  0.00437556 0.\n",
      " 0.00810185]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el vector de scores para todos los textos\n",
    "y_pred = np.array([get_text_score(t) for t in texts_sentiments[\"Text\"]], dtype=np.float32)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. mínimo: 0.0; Val. máximo: 0.023986486718058586\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el rango de valores de las predicciones\n",
    "y_pred_min = y_pred.min()\n",
    "y_pred_max = y_pred.max()\n",
    "print(f\"Val. mínimo: {y_pred_min}; Val. máximo: {y_pred_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. mínimo: -1.0; Val. máximo: 1.0\n",
      "\n",
      "Array normalizado al intervalo [-1, 1]:\n",
      "[ 1.         -1.         -1.         -1.         -1.         -1.\n",
      " -0.89660186 -0.6571534  -1.         -1.         -1.         -1.\n",
      " -1.         -0.53470826 -0.87852526 -1.         -0.21041399 -1.\n",
      " -1.         -1.          0.48397052 -1.         -0.04671931 -1.\n",
      " -1.         -1.         -1.          0.37686336  0.13288426 -1.\n",
      " -1.         -0.63747704 -1.         -1.         -1.         -0.5611564\n",
      " -0.50438297 -1.         -1.         -1.         -1.         -1.\n",
      "  0.36203575  0.29341698 -1.         -1.         -1.         -1.\n",
      " -0.15316904 -0.34859157 -0.6898055  -1.         -0.85524255 -0.7394366\n",
      " -0.8009585  -1.         -1.         -0.91491807 -1.         -0.91066396\n",
      " -1.         -0.8841941  -0.82086265 -0.9143353  -0.63516486 -1.\n",
      " -0.32446533]\n"
     ]
    }
   ],
   "source": [
    "# Normalizamos las predicciones al rango [-1, 1]\n",
    "y_pred_norm = 2 * ((y_pred - y_pred_min) / (y_pred_max - y_pred_min)) - 1\n",
    "print(f\"Val. mínimo: {y_pred_norm.min()}; Val. máximo: {y_pred_norm.max()}\")\n",
    "print(\"\\nArray normalizado al intervalo [-1, 1]:\")\n",
    "print(y_pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones codificadas:\n",
      "[1 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 0 2 0 2 2 2 2 0 0 2 2 0 2 2 2 0 0\n",
      " 2 2 2 2 2 0 0 2 2 2 2 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "y_pred_encoded = y_pred_norm.copy()\n",
    "positive_pred = (y_pred_encoded > threshold)\n",
    "negative_pred = (y_pred_encoded < threshold)\n",
    "neutral_pred = (y_pred_encoded >= -threshold) & (y_pred_encoded <= threshold)\n",
    "y_pred_encoded[positive_pred] = dicc_encode[\"Positive\"]\n",
    "y_pred_encoded[negative_pred] = dicc_encode[\"Negative\"]\n",
    "y_pred_encoded[neutral_pred] = dicc_encode[\"Neutral\"]\n",
    "y_pred_encoded = y_pred_encoded.astype(np.uint8)\n",
    "\n",
    "print(\"Predicciones codificadas:\")\n",
    "print(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1044776119402985\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las métricas\n",
    "y_real = np.array(texts_sentiments[\"Sentiment\"], dtype=np.uint8)\n",
    "print(f\"Accuracy: {accuracy_score(y_real, y_pred_encoded)}\")\n",
    "print(f\"Precision: {precision_score(y_real, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_real, y_pred)}\")\n",
    "print(f\"F-score: {f1_score(y_real, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
