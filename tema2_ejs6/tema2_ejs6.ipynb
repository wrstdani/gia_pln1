{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from pywsd import simple_lesk\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_sw = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 1:** Se quiere desarrollar un evaluador de sentimientos basado en el uso de un recursos ling칲칤stico externo, en concreto, las listas de palabras de opini칩n que tiene NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion1 = \"Visceral, stunning and relentless film making. Dicaprio's Herculean, almost purely physical performance\" \\\n",
    "            \"and Hardy's wide eyed intensity coupled with the almost overwhelming beauty of the landscape - those \" \\\n",
    "            \"trees, the natural light, the sun peeking through the clouds, rendered the proceedings down to savage\" \\\n",
    "            \"poetry. A hypnotic, beautiful, exhausting film.\"\n",
    "\n",
    "opinion2 = \"I saw this film on Friday. For the first 40 minutes involving spoken dialogue they need not have \" \\\n",
    "            \"bothered. For me the dialogue was totally unintelligible with grunting, southern states drawl, \" \\\n",
    "            \"and coarse accent that made it impossible to understand what they were saying.\"\n",
    "\n",
    "opinion3 = \"It was a idiotic film that produces a magnificent fascination.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "    word_tokenized = [word_tokenize(s) for s in sent_tokenized]\n",
    "    return word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            if w in opinion_lexicon.positive() and w in opinion_lexicon.negative():\n",
    "                score += 0\n",
    "            elif w in opinion_lexicon.positive():\n",
    "                score += 1\n",
    "            elif w in opinion_lexicon.negative():\n",
    "                score -= 1\n",
    "    if score == 0:\n",
    "        return \"neutro\", score\n",
    "    elif score > 0:\n",
    "        return \"pos\", score\n",
    "    else:\n",
    "        return \"neg\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 1\n",
    "print(classify(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', -4)\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 2\n",
    "print(classify(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 3\n",
    "print(classify(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 2:** Se pide lo mismo que en el ejercicio anterior, pero en este caso utilizando SentiWordNet (disponible en NLTK). Esta base de datos proporciona valores positivos y negativos para ciertas palabras en un rango entre -1 y 1. Se puede seguir la misma idea de algoritmo que en el caso anterior, pero hay que tener en cuenta que SentiWordNet nos proporciona puntuaciones para los diferentes sentidos que tiene una palabra. Se puede entonces considerar la puntuaci칩n de todos los sentidos de la misma palabra, restando a lo positivo la puntuaci칩n negativa. Puede ser interesante que la puntuaci칩n global se promedie de acuerdo con el n칰mero de sentidos.  Utilizar como entrada las mismas opiniones del ejercicio anterior. 쮼l resultado es mejor o peor que el conseguido con el algoritmo del ejercicio 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_swn(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    total_score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            senti_synsets = list(swn.senti_synsets(w))\n",
    "            word_score = 0\n",
    "            for senti_synset in senti_synsets:\n",
    "                word_score += senti_synset.obj_score()\n",
    "            if len(senti_synsets) > 0:\n",
    "                total_score += word_score / len(senti_synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.784353633954698\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 1\n",
    "print(classify_swn(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.681840555278054\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 2\n",
    "print(classify_swn(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.056547619047619\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 3\n",
    "print(classify_swn(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 2.1:** Hacer una variante del ejercicio donde se tengan en cuenta primero la categor칤a gramatical del token para considerar 칰nicamente los scores de los sentidos que coincidan con la categor칤a gramatical dada. 쮿a mejorado el resultado o ha empeorado con respecto a versiones anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n auxiliar para convertir un\n",
    "# tag generado por nltk.pos_tag()\n",
    "# en una categ. gramatical de \n",
    "# WordNet\n",
    "def tag2wn(tag):\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wn.VERB\n",
    "    elif tag.startswith(\"J\"):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def classify_swn_gram(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    tags = [nltk.pos_tag(s) for s in word_tokenized]\n",
    "    total_score = 0\n",
    "    for s in tags:\n",
    "        for w, t in s:\n",
    "            synsets = list(swn.senti_synsets(w, tag2wn(t)))\n",
    "            word_score = 0\n",
    "            for synset in synsets:\n",
    "                word_score += synset.obj_score()\n",
    "            if len(synsets) > 0:\n",
    "                total_score += word_score / len(synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.805654761904766\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 1\n",
    "print(classify_swn_gram(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.569603892348248\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 2\n",
    "print(classify_swn_gram(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.053113553113552\n"
     ]
    }
   ],
   "source": [
    "# Opini칩n 3\n",
    "print(classify_swn_gram(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que la mejora es m치s bien leve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 3:** Se pide extender lo que se ha hecho en los ejercicios anteriores, pero ampliado para todas las opiniones contenidas en un fichero .csv (textsSentimentsPNN.csv), donde cada opini칩n est치 anotada con su polaridad (positiva, negativa o neutra). Un ejemplo del formato del archivo se muestra a continuaci칩n, en la primera columna estar칤a el texto de la opini칩n y en la segunda el sentimiento (Positive, Negative o Neutral).  \n",
    " \n",
    "    Utilizando de nuevo SentiWordNet se pide predecir la polaridad de cada mensaje. Una vez que se tenga la polaridad de cada mensaje, utilizar las m칠tricas del paquete sklearn.metrics de la librer칤a scikit-learn para obtener los valores de accuracy, precisi칩n, recall y f-measure. En definitiva, se quiere poder cuantificar si se est치n clasificando bien las opiniones seg칰n su polaridad. Cuanto m치s cercano a 1 sea el valor que se obtiene con estas m칠tricas, mejor estar치 clasificando cada mensaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! 游눩</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!  Positive\n",
       "1           Traffic was terrible this morning.  Negative\n",
       "2          Just finished an amazing workout! 游눩  Positive\n",
       "3  Excited about the upcoming weekend getaway!  Positive\n",
       "4  Trying out a new recipe for dinner tonight.   Neutral"
      ]
     },
     "execution_count": 1304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos el archivo \".csv\" con pandas\n",
    "texts_sentiments = pd.read_csv(\"data/textsSentimentsPNN.csv\")\n",
    "\n",
    "# Mostramos las 5 primeras filas\n",
    "texts_sentiments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1     False\n",
       "2      True\n",
       "3      True\n",
       "4     False\n",
       "      ...  \n",
       "62    False\n",
       "63    False\n",
       "64    False\n",
       "65    False\n",
       "66    False\n",
       "Name: Sentiment, Length: 67, dtype: bool"
      ]
     },
     "execution_count": 1305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_sentiments[\"Sentiment\"] == \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! 游눩</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!         1\n",
       "1           Traffic was terrible this morning.         2\n",
       "2          Just finished an amazing workout! 游눩         1\n",
       "3  Excited about the upcoming weekend getaway!         1\n",
       "4  Trying out a new recipe for dinner tonight.         0"
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un diccionario para codificar las etiquetas\n",
    "dicc_encode = {\n",
    "    \"Neutral\": 0,\n",
    "    \"Positive\": 1,\n",
    "    \"Negative\": 2\n",
    "}\n",
    "\n",
    "# Aplicamos la transformaci칩n y comprobamos el resultado\n",
    "for key, value in dicc_encode.items():\n",
    "    mask = (texts_sentiments[\"Sentiment\"] == key)\n",
    "    texts_sentiments.loc[mask, \"Sentiment\"] = value\n",
    "\n",
    "texts_sentiments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Enjoying a beautiful day at the park!\n",
      "Texto preprocesado: (['Enjoying a beautiful day at the park!'], [['Enjoying', 'beautiful', 'day', 'park']])\n"
     ]
    }
   ],
   "source": [
    "# Funci칩n para preprocesar cada texto\n",
    "def preprocess_text(text):\n",
    "    # Tokenizamos el texto en sentencias\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "\n",
    "    # Tokenizamos cada sentencia en palabras,\n",
    "    # eliminando a su vez la puntuaci칩n\n",
    "    word_tokenized_np = [regexp_tokenize(s.lower(), r\"[\\w\\d]+\") for s in sent_tokenized]\n",
    "\n",
    "    # Eliminamos las stopwords\n",
    "    word_tokenized_np_nsw = []\n",
    "    for s in word_tokenized_np:\n",
    "        word_tokenized_np_nsw.append([w for w in s if w not in english_sw])\n",
    "    \n",
    "    # Lematizamos\n",
    "    lemmatized_tokens = []\n",
    "    for s in word_tokenized_np_nsw:\n",
    "        lemmatized_tokens.append([WordNetLemmatizer().lemmatize(w) for w in s])\n",
    "\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Mostramos un ejemplo de c칩mo quedar칤a un texto preprocesado\n",
    "print(f\"Texto original: {texts_sentiments[\"Text\"][0]}\")\n",
    "print(f\"Texto preprocesado: {preprocess_text(texts_sentiments[\"Text\"][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: Enjoying a beautiful day at the park!\n",
      "Score: 0.023986486486486484\n"
     ]
    }
   ],
   "source": [
    "# Funci칩n para obtener el score de un texto\n",
    "def get_text_score(text):\n",
    "    preprocessed = preprocess_text(text)\n",
    "    tags = [nltk.pos_tag(s) for s in preprocessed]\n",
    "    total_score = 0\n",
    "    for s_idx in range(len(preprocessed)):\n",
    "        sent_score = 0\n",
    "        for w, t in tags[s_idx]:\n",
    "            synset = simple_lesk(\" \".join(preprocessed[s_idx]), w, tag2wn(t))\n",
    "            if synset is not None:\n",
    "                \n",
    "\n",
    "# Mostramos un ejemplo de score para un texto\n",
    "print(f\"Texto: {texts_sentiments[\"Text\"][0]}\")\n",
    "print(f\"Score: {get_text_score(texts_sentiments[\"Text\"][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02398649 0.         0.         0.         0.         0.\n",
      " 0.00124008 0.00411184 0.         0.         0.         0.\n",
      " 0.         0.00558036 0.00145688 0.         0.0094697  0.\n",
      " 0.         0.         0.01779762 0.         0.01143293 0.\n",
      " 0.         0.         0.         0.01651306 0.01358696 0.\n",
      " 0.         0.00434783 0.         0.         0.         0.00526316\n",
      " 0.00594406 0.         0.         0.         0.         0.\n",
      " 0.01633523 0.01551227 0.         0.         0.         0.\n",
      " 0.01015625 0.0078125  0.00372024 0.         0.00173611 0.003125\n",
      " 0.00238715 0.         0.         0.00102041 0.         0.00107143\n",
      " 0.         0.00138889 0.00214844 0.0010274  0.00437556 0.\n",
      " 0.00810185]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el vector de scores para todos los textos\n",
    "y_pred = np.array([get_text_score(t) for t in texts_sentiments[\"Text\"]], dtype=np.float32)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. m칤nimo: 0.0; Val. m치ximo: 0.023986486718058586\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el rango de valores de las predicciones\n",
    "y_pred_min = y_pred.min()\n",
    "y_pred_max = y_pred.max()\n",
    "print(f\"Val. m칤nimo: {y_pred_min}; Val. m치ximo: {y_pred_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. m칤nimo: -1.0; Val. m치ximo: 1.0\n",
      "\n",
      "Array normalizado al intervalo [-1, 1]:\n",
      "[ 1.         -1.         -1.         -1.         -1.         -1.\n",
      " -0.89660186 -0.6571534  -1.         -1.         -1.         -1.\n",
      " -1.         -0.53470826 -0.87852526 -1.         -0.21041399 -1.\n",
      " -1.         -1.          0.48397052 -1.         -0.04671931 -1.\n",
      " -1.         -1.         -1.          0.37686336  0.13288426 -1.\n",
      " -1.         -0.63747704 -1.         -1.         -1.         -0.5611564\n",
      " -0.50438297 -1.         -1.         -1.         -1.         -1.\n",
      "  0.36203575  0.29341698 -1.         -1.         -1.         -1.\n",
      " -0.15316904 -0.34859157 -0.6898055  -1.         -0.85524255 -0.7394366\n",
      " -0.8009585  -1.         -1.         -0.91491807 -1.         -0.91066396\n",
      " -1.         -0.8841941  -0.82086265 -0.9143353  -0.63516486 -1.\n",
      " -0.32446533]\n"
     ]
    }
   ],
   "source": [
    "# Normalizamos las predicciones al rango [-1, 1]\n",
    "y_pred_norm = 2 * ((y_pred - y_pred_min) / (y_pred_max - y_pred_min)) - 1\n",
    "print(f\"Val. m칤nimo: {y_pred_norm.min()}; Val. m치ximo: {y_pred_norm.max()}\")\n",
    "print(\"\\nArray normalizado al intervalo [-1, 1]:\")\n",
    "print(y_pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones codificadas:\n",
      "[1 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 0 2 0 2 2 2 2 0 0 2 2 0 2 2 2 0 0\n",
      " 2 2 2 2 2 0 0 2 2 2 2 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "y_pred_encoded = y_pred_norm.copy()\n",
    "positive_pred = (y_pred_encoded > threshold)\n",
    "negative_pred = (y_pred_encoded < threshold)\n",
    "neutral_pred = (y_pred_encoded >= -threshold) & (y_pred_encoded <= threshold)\n",
    "y_pred_encoded[positive_pred] = dicc_encode[\"Positive\"]\n",
    "y_pred_encoded[negative_pred] = dicc_encode[\"Negative\"]\n",
    "y_pred_encoded[neutral_pred] = dicc_encode[\"Neutral\"]\n",
    "y_pred_encoded = y_pred_encoded.astype(np.uint8)\n",
    "\n",
    "print(\"Predicciones codificadas:\")\n",
    "print(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1044776119402985\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las m칠tricas\n",
    "y_real = np.array(texts_sentiments[\"Sentiment\"], dtype=np.uint8)\n",
    "print(f\"Accuracy: {accuracy_score(y_real, y_pred_encoded)}\")\n",
    "print(f\"Precision: {precision_score(y_real, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_real, y_pred)}\")\n",
    "print(f\"F-score: {f1_score(y_real, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
