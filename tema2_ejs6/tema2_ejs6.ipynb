{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from pywsd import adapted_lesk\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_sw = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 1:** Se quiere desarrollar un evaluador de sentimientos basado en el uso de un recursos lingüístico externo, en concreto, las listas de palabras de opinión que tiene NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion1 = \"Visceral, stunning and relentless film making. Dicaprio's Herculean, almost purely physical performance\" \\\n",
    "            \"and Hardy's wide eyed intensity coupled with the almost overwhelming beauty of the landscape - those \" \\\n",
    "            \"trees, the natural light, the sun peeking through the clouds, rendered the proceedings down to savage\" \\\n",
    "            \"poetry. A hypnotic, beautiful, exhausting film.\"\n",
    "\n",
    "opinion2 = \"I saw this film on Friday. For the first 40 minutes involving spoken dialogue they need not have \" \\\n",
    "            \"bothered. For me the dialogue was totally unintelligible with grunting, southern states drawl, \" \\\n",
    "            \"and coarse accent that made it impossible to understand what they were saying.\"\n",
    "\n",
    "opinion3 = \"It was a idiotic film that produces a magnificent fascination.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "    word_tokenized = [word_tokenize(s) for s in sent_tokenized]\n",
    "    return word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            if w in opinion_lexicon.positive() and w in opinion_lexicon.negative():\n",
    "                score += 0\n",
    "            elif w in opinion_lexicon.positive():\n",
    "                score += 1\n",
    "            elif w in opinion_lexicon.negative():\n",
    "                score -= 1\n",
    "    if score == 0:\n",
    "        return \"neutro\", score\n",
    "    elif score > 0:\n",
    "        return \"pos\", score\n",
    "    else:\n",
    "        return \"neg\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opinión 1\n",
    "print(classify(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', -4)\n"
     ]
    }
   ],
   "source": [
    "# Opinión 2\n",
    "print(classify(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1)\n"
     ]
    }
   ],
   "source": [
    "# Opinión 3\n",
    "print(classify(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 2:** Se pide lo mismo que en el ejercicio anterior, pero en este caso utilizando SentiWordNet (disponible en NLTK). Esta base de datos proporciona valores positivos y negativos para ciertas palabras en un rango entre -1 y 1. Se puede seguir la misma idea de algoritmo que en el caso anterior, pero hay que tener en cuenta que SentiWordNet nos proporciona puntuaciones para los diferentes sentidos que tiene una palabra. Se puede entonces considerar la puntuación de todos los sentidos de la misma palabra, restando a lo positivo la puntuación negativa. Puede ser interesante que la puntuación global se promedie de acuerdo con el número de sentidos.  Utilizar como entrada las mismas opiniones del ejercicio anterior. ¿El resultado es mejor o peor que el conseguido con el algoritmo del ejercicio 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_swn(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    total_score = 0\n",
    "    for s in word_tokenized:\n",
    "        for w in s:\n",
    "            synsets = list(swn.senti_synsets(w))\n",
    "            word_score = 0\n",
    "            for synset in synsets:\n",
    "                word_score += (synset.pos_score() - synset.neg_score())\n",
    "            if len(synsets) > 0:\n",
    "                total_score += word_score / len(synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4219623904464331\n"
     ]
    }
   ],
   "source": [
    "# Opinión 1\n",
    "print(classify_swn(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.25598923992673994\n"
     ]
    }
   ],
   "source": [
    "# Opinión 2\n",
    "print(classify_swn(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7648809523809523\n"
     ]
    }
   ],
   "source": [
    "# Opinión 3\n",
    "print(classify_swn(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ejercicio 2.1:** Hacer una variante del ejercicio donde se tengan en cuenta primero la categoría gramatical del token para considerar únicamente los scores de los sentidos que coincidan con la categoría gramatical dada. ¿Ha mejorado el resultado o ha empeorado con respecto a versiones anteriores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para convertir un\n",
    "# tag generado por nltk.pos_tag()\n",
    "# en una categ. gramatical de \n",
    "# WordNet\n",
    "def tag2wn(tag):\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wn.VERB\n",
    "    elif tag.startswith(\"J\"):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def classify_swn_gram(text):\n",
    "    word_tokenized = tokenize_text(text)\n",
    "    tags = [nltk.pos_tag(s) for s in word_tokenized]\n",
    "    total_score = 0\n",
    "    for s in tags:\n",
    "        for w, t in s:\n",
    "            synsets = list(swn.senti_synsets(w, tag2wn(t)))\n",
    "            word_score = 0\n",
    "            for synset in synsets:\n",
    "                word_score += (synset.pos_score() - synset.neg_score())\n",
    "            if len(synsets) > 0:\n",
    "                total_score += word_score / len(synsets)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5139880952380951\n"
     ]
    }
   ],
   "source": [
    "# Opinión 1\n",
    "print(classify_swn_gram(opinion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05469148771028469\n"
     ]
    }
   ],
   "source": [
    "# Opinión 2\n",
    "print(classify_swn_gram(opinion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655677655677655\n"
     ]
    }
   ],
   "source": [
    "# Opinión 3\n",
    "print(classify_swn_gram(opinion3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que la mejora es más bien leve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Ejercicio 3:** Se pide extender lo que se ha hecho en los ejercicios anteriores, pero ampliado para todas las opiniones contenidas en un fichero .csv (textsSentimentsPNN.csv), donde cada opinión está anotada con su polaridad (positiva, negativa o neutra). Un ejemplo del formato del archivo se muestra a continuación, en la primera columna estaría el texto de la opinión y en la segunda el sentimiento (Positive, Negative o Neutral).  \n",
    " \n",
    "    Utilizando de nuevo SentiWordNet se pide predecir la polaridad de cada mensaje. Una vez que se tenga la polaridad de cada mensaje, utilizar las métricas del paquete sklearn.metrics de la librería scikit-learn para obtener los valores de accuracy, precisión, recall y f-measure. En definitiva, se quiere poder cuantificar si se están clasificando bien las opiniones según su polaridad. Cuanto más cercano a 1 sea el valor que se obtiene con estas métricas, mejor estará clasificando cada mensaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! 💪</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!  Positive\n",
       "1           Traffic was terrible this morning.  Negative\n",
       "2          Just finished an amazing workout! 💪  Positive\n",
       "3  Excited about the upcoming weekend getaway!  Positive\n",
       "4  Trying out a new recipe for dinner tonight.   Neutral"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentiments = pd.read_csv(\"data/textsSentimentsPNN.csv\")\n",
    "text_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! 💪</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Sentiment\n",
       "0        Enjoying a beautiful day at the park!         1\n",
       "1           Traffic was terrible this morning.         2\n",
       "2          Just finished an amazing workout! 💪         1\n",
       "3  Excited about the upcoming weekend getaway!         1\n",
       "4  Trying out a new recipe for dinner tonight.         0"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sustituimos:\n",
    "# Positive -> 1\n",
    "# Neutral -> 0\n",
    "# Negative -> 2\n",
    "positive = text_sentiments[\"Sentiment\"] == \"Positive\"\n",
    "neutral = text_sentiments[\"Sentiment\"] == \"Neutral\"\n",
    "negative = text_sentiments[\"Sentiment\"] == \"Negative\"\n",
    "\n",
    "text_sentiments.loc[positive, \"Sentiment\"] = 1\n",
    "text_sentiments.loc[neutral, \"Sentiment\"] = 0\n",
    "text_sentiments.loc[negative, \"Sentiment\"] = 2\n",
    "\n",
    "text_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para tokenizar el texto\n",
    "def preprocess_text(text):\n",
    "    sent_tokenized = PunktSentenceTokenizer().tokenize(text)\n",
    "    word_tokenized_no_punct = [regexp_tokenize(s, r\"[\\w\\d]+\") for s in sent_tokenized]\n",
    "    # Eliminamos puntuación y stopwords\n",
    "    no_punct_no_sw = []\n",
    "    for s in word_tokenized_no_punct:\n",
    "        no_punct_no_sw.append([w for w in s if w not in english_sw])\n",
    "\n",
    "    tagged = [nltk.pos_tag(s) for s in no_punct_no_sw]\n",
    "\n",
    "    return tagged\n",
    "\n",
    "# Clasificamos cada texto aplicando WSD previamente\n",
    "def classify_text(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    total_score = 0\n",
    "    for s in preprocessed_text:\n",
    "        sent_score = 0\n",
    "        for w, t in s:\n",
    "            senti_synsets = swn.senti_synsets(w, tag2wn(t))\n",
    "            for senti_synset in senti_synsets:\n",
    "                if senti_synset is not None:\n",
    "                    sent_score += (senti_synset.pos_score() - senti_synset.neg_score())\n",
    "        total_score += sent_score\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos y normalizamos las predicciones\n",
    "sentiments_pred = [classify_text(text) for text in text_sentiments[\"Text\"]]\n",
    "min_pred = min(sentiments_pred)\n",
    "max_pred = max(sentiments_pred)\n",
    "\n",
    "normalized_pred = [2 * ((pred - min_pred) / (max_pred - min_pred)) - 1 for pred in sentiments_pred]\n",
    "normalized_pred = np.array(normalized_pred).astype(np.float32)\n",
    "\n",
    "threshold = 0.1\n",
    "positive_pred = normalized_pred > threshold\n",
    "negative_pred = normalized_pred < -threshold\n",
    "neutral_pred = (normalized_pred >= -threshold) & (normalized_pred <= threshold)\n",
    "y_pred = normalized_pred.copy()\n",
    "y_pred[positive_pred] = 1\n",
    "y_pred[neutral_pred] = 0\n",
    "y_pred[negative_pred] = 2\n",
    "y_pred = y_pred.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1044776119402985\n",
      "Precision: 0.6753731343283582\n",
      "Recall: 0.1044776119402985\n",
      "F-score: 0.09097892888498683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wrst/miniconda3/envs/pln1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(text_sentiments[\"Sentiment\"], dtype=np.uint8)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred, average=\"weighted\")}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred, average=\"weighted\")}\")\n",
    "print(f\"F-score: {f1_score(y_true, y_pred, average=\"weighted\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1 0 1 1 1 2 0 1 2 1 1 0 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.    -2.625  0.25   0.5    0.5   -1.     2.25   1.375  0.125 -0.375\n",
      "  1.25   0.125  0.875  1.75   2.375  1.875  2.125 -0.125  0.25  -3.375\n",
      " 15.     0.875  2.375  0.875  0.5    0.375  0.625 12.125  2.625  0.125\n",
      " -1.5    3.     1.     0.375  0.     2.75   3.     0.625  0.5    0.\n",
      "  0.5    0.75   3.5   12.75   0.75   0.625  0.75   3.25   2.625  1.375\n",
      "  1.625 -0.125 -0.125  1.75   4.     1.25   0.625  2.875  0.375  1.875\n",
      "  0.    -0.125  2.25   1.375  1.875  1.625  3.   ]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
