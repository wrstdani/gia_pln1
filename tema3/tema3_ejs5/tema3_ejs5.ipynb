{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wrstdani/anaconda3/envs/pln1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from sense2vec import Sense2Vec\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 1\n",
    "- Una de las principales limitaciones presentes en la implementación original de Word2Vec es la asignación de un único vector estático a cada palabra. Además de los posibles problemas relacionados con las palabras fuera del vocabulario de entrenamiento, este hecho puede suponer un gran inconveniente a la hora de analizar palabras polisémicas con diversas categorías gramaticales, no pudiendo diferenciar sus posibles acepciones.\n",
    "\n",
    "- En este contexto, Sense2Vec surge como una posible solución a este problema. En lugar de tratar cada token como una entidad única, Sense2Vec propone realizar un etiquetado previo de los tokens de entrenamiento con su correspondiente etiqueta gramatical o etiqueta POS. Por medio de la incorporación de esta información lingüística, Sense2Vec permite generar representaciones diferenciadas de palabras según su categoría gramatical, facilitando el análisis de palabras polisémicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!mkdir models &&     wget -P  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz &&     tar -xvzf models/s2v_reddit_2015_md.tar.gz     rm models/s2v_reddit_2015_md.tar.gz\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!mkdir models && \\\n",
    "    wget -P  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz && \\\n",
    "    tar -xvzf models/s2v_reddit_2015_md.tar.gz \\\n",
    "    rm models/s2v_reddit_2015_md.tar.gz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2v = Sense2Vec().from_disk(\"models/s2v_old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se pide:\n",
    "    - Calcular con Sense2Vec los embeddings de la palabra \"watch\" tanto cuando ejerce la categoría gramatical de verbo como cuando ejerce la de nombre. ¿Son diferentes los vectores?\n",
    "    - Dado el conjunto de frases [\"You must watch the light movie.\", \"He gave me a watch with a light.\"], elimina las palabras vacías y signos de puntuación. Posteriormente, obtén con Sense2Vec las tres palabras más similares de los tokens resultantes, empleando para ello su categoría gramatical.\n",
    "    - Usando la librería Gensim, repite lo anterior para el modelo preentrenado \"word2vec-google-news-300\". ¿Qué diferencias encuentras entre Word2Vec y Sense2Vec? ¿Cuál funciona mejor y sobre qué contextos?\n",
    "    - Con Word2Vec y Sense2Vec, repite lo anterior para el conjunto de frases [\"I went to the bank to deposit my money.\", \"The land along the river bank has vegetation.\"]. ¿Qué ocurre en esta ocasión? ¿A qué se debe?\n",
    "    - Calcula la similitud coseno entre los siguientes pares con la categoría gramatical indicada:\n",
    "        - (\"watch|NOUN\", \"watch|VERB\") ¿Es alto este valor? ¿A qué puede deberse?\n",
    "        - (\"watch|NOUN\", \"clock|NOUN\")\n",
    "        - (\"watch|NOUN\", \"view|VERB\")\n",
    "        - (\"watch|VERB\", \"clock|NOUN\")\n",
    "        - (\"watch|VERB\", \"view|VERB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener embeddings con S2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener embeddings de \"watch\"\n",
    "watch_verb = dict(s2v.items())[\"watch|VERB\"]\n",
    "watch_noun = dict(s2v.items())[\"watch|NOUN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener palabras más similares (S2V vs. W2V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sentencias tokenizadas y etiquetadas (POS tagged):\n",
      "[[('watch', 'VERB'), ('light', 'ADJ'), ('movie', 'NOUN')], [('gave', 'VERB'), ('watch', 'NOUN'), ('light', 'NOUN')]]\n",
      "- 3 palabras más similares de...\n",
      "    - (watch|VERB):\n",
      "        - watching siendo un VERB tiene un 89.33% de similitud\n",
      "        - watching siendo un NOUN tiene un 83.48% de similitud\n",
      "        - watched siendo un VERB tiene un 82.30% de similitud\n",
      "    - (light|ADJ):\n",
      "        - dark siendo un ADJ tiene un 80.24% de similitud\n",
      "        - bright siendo un ADJ tiene un 79.52% de similitud\n",
      "        - light siendo un NOUN tiene un 76.95% de similitud\n",
      "    - (movie|NOUN):\n",
      "        - whole_movie siendo un NOUN tiene un 90.32% de similitud\n",
      "        - good_movie siendo un NOUN tiene un 90.19% de similitud\n",
      "        - terrible_movie siendo un NOUN tiene un 89.95% de similitud\n",
      "    - (gave|VERB):\n",
      "        - Gave siendo un VERB tiene un 84.35% de similitud\n",
      "        - giving siendo un VERB tiene un 80.08% de similitud\n",
      "        - had siendo un VERB tiene un 80.02% de similitud\n",
      "    - (watch|NOUN):\n",
      "        - wristwatch siendo un NOUN tiene un 76.19% de similitud\n",
      "        - watches siendo un NOUN tiene un 75.81% de similitud\n",
      "        - just_the_watch siendo un NOUN tiene un 75.02% de similitud\n",
      "    - (light|NOUN):\n",
      "        - _Light siendo un NOUN tiene un 85.90% de similitud\n",
      "        - white_light siendo un NOUN tiene un 83.65% de similitud\n",
      "        - _light siendo un NOUN tiene un 81.28% de similitud\n"
     ]
    }
   ],
   "source": [
    "sents = [\n",
    "    \"You must watch a light movie.\",\n",
    "    \"He gave me a watch with a light.\"\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tok_tagged_sents = [[(token.lower_, token.pos_) for token in nlp(s) if (token.is_alpha and (not token.is_stop))] for s in sents]\n",
    "\n",
    "print(f\"- Sentencias tokenizadas y etiquetadas (POS tagged):\\n{tok_tagged_sents}\")\n",
    "\n",
    "print(\"- 3 palabras más similares de...\")\n",
    "for s in tok_tagged_sents:\n",
    "    for word, pos_tag in s:\n",
    "        print(f\"    - ({word}|{pos_tag}):\")\n",
    "        three_most_similar = s2v.most_similar(\"|\".join([word, pos_tag]), n=3)\n",
    "        for ms in three_most_similar:\n",
    "            w = ms[0].split(\"|\")[0]\n",
    "            pt = ms[0].split(\"|\")[1]\n",
    "            sim = ms[1]\n",
    "            print(f\"        - {w} siendo un {pt} tiene un {sim*100:.2f}% de similitud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 3 palabras más similares de...\n",
      "    - watch:\n",
      "        - watching tiene un 78.36% de similitud\n",
      "        - watched tiene un 66.77% de similitud\n",
      "        - Watching tiene un 63.86% de similitud\n",
      "    - light:\n",
      "        - lights tiene un 55.06% de similitud\n",
      "        - yellowish_glow tiene un 54.85% de similitud\n",
      "        - illumination tiene un 53.43% de similitud\n",
      "    - movie:\n",
      "        - film tiene un 86.77% de similitud\n",
      "        - movies tiene un 80.13% de similitud\n",
      "        - films tiene un 73.63% de similitud\n",
      "    - gave:\n",
      "        - give tiene un 74.12% de similitud\n",
      "        - giving tiene un 74.06% de similitud\n",
      "        - gives tiene un 66.45% de similitud\n",
      "    - watch:\n",
      "        - watching tiene un 78.36% de similitud\n",
      "        - watched tiene un 66.77% de similitud\n",
      "        - Watching tiene un 63.86% de similitud\n",
      "    - light:\n",
      "        - lights tiene un 55.06% de similitud\n",
      "        - yellowish_glow tiene un 54.85% de similitud\n",
      "        - illumination tiene un 53.43% de similitud\n"
     ]
    }
   ],
   "source": [
    "# Utilizar Word2Vec\n",
    "w2v = gensim_api.load(\"word2vec-google-news-300\")\n",
    "print(\"- 3 palabras más similares de...\")\n",
    "for s in tok_tagged_sents:\n",
    "    for word, pos_tag in s:\n",
    "        print(f\"    - {word}:\")\n",
    "        three_most_similar = w2v.most_similar(word, topn=3)\n",
    "        for ms in three_most_similar:\n",
    "            w = ms[0]\n",
    "            sim = ms[1]\n",
    "            print(f\"        - {w} tiene un {sim*100:.2f}% de similitud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sentencias tokenizadas y etiquetadas (POS tagged):\n",
      "[[('went', 'VERB'), ('bank', 'NOUN'), ('deposit', 'VERB'), ('money', 'NOUN')], [('land', 'NOUN'), ('river', 'NOUN'), ('bank', 'NOUN'), ('vegetation', 'NOUN')]]\n",
      "- 3 palabras más similares de...\n",
      "    - (went|VERB):\n",
      "         - Sense2Vec:\n",
      "            - went siendo un ADJ tiene un 88.34% de similitud\n",
      "            - came siendo un VERB tiene un 88.03% de similitud\n",
      "            - wen't siendo un VERB tiene un 87.92% de similitud\n",
      "         - Word2Vec:\n",
      "            - came tiene un 71.42% de similitud\n",
      "            - ran tiene un 67.15% de similitud\n",
      "            - gone tiene un 64.05% de similitud\n",
      "    - (bank|NOUN):\n",
      "         - Sense2Vec:\n",
      "            - local_bank siendo un NOUN tiene un 88.59% de similitud\n",
      "            - bank_account siendo un NOUN tiene un 86.53% de similitud\n",
      "            - same_bank siendo un NOUN tiene un 85.36% de similitud\n",
      "         - Word2Vec:\n",
      "            - banks tiene un 74.41% de similitud\n",
      "            - banking tiene un 69.02% de similitud\n",
      "            - Bank tiene un 66.99% de similitud\n",
      "    - (deposit|VERB):\n",
      "         - Sense2Vec:\n",
      "            - depositing siendo un VERB tiene un 89.51% de similitud\n",
      "            - Deposit siendo un VERB tiene un 87.19% de similitud\n",
      "            - deposite siendo un VERB tiene un 79.75% de similitud\n",
      "         - Word2Vec:\n",
      "            - deposits tiene un 81.11% de similitud\n",
      "            - Deposit tiene un 76.86% de similitud\n",
      "            - Deposits tiene un 64.26% de similitud\n",
      "    - (money|NOUN):\n",
      "         - Sense2Vec:\n",
      "            - _money siendo un NOUN tiene un 91.45% de similitud\n",
      "            - even_more_money siendo un NOUN tiene un 89.20% de similitud\n",
      "            - own_money siendo un NOUN tiene un 88.99% de similitud\n",
      "         - Word2Vec:\n",
      "            - monies tiene un 71.65% de similitud\n",
      "            - funds tiene un 70.55% de similitud\n",
      "            - moneys tiene un 62.89% de similitud\n",
      "    - (land|NOUN):\n",
      "         - Sense2Vec:\n",
      "            - own_land siendo un NOUN tiene un 82.91% de similitud\n",
      "            - other_land siendo un NOUN tiene un 81.24% de similitud\n",
      "            - lands siendo un NOUN tiene un 77.98% de similitud\n",
      "         - Word2Vec:\n",
      "            - lands tiene un 74.58% de similitud\n",
      "            - farmland tiene un 68.34% de similitud\n",
      "            - acres tiene un 61.54% de similitud\n",
      "    - (river|NOUN):\n",
      "         - Sense2Vec:\n",
      "            - lake siendo un NOUN tiene un 87.70% de similitud\n",
      "            - creek siendo un NOUN tiene un 85.62% de similitud\n",
      "            - shoreline siendo un NOUN tiene un 85.04% de similitud\n",
      "         - Word2Vec:\n",
      "            - creek tiene un 79.94% de similitud\n",
      "            - lake tiene un 79.20% de similitud\n",
      "            - rivers tiene un 77.78% de similitud\n",
      "    - (bank|NOUN):\n",
      "         - Sense2Vec:\n",
      "            - local_bank siendo un NOUN tiene un 88.59% de similitud\n",
      "            - bank_account siendo un NOUN tiene un 86.53% de similitud\n",
      "            - same_bank siendo un NOUN tiene un 85.36% de similitud\n",
      "         - Word2Vec:\n",
      "            - banks tiene un 74.41% de similitud\n",
      "            - banking tiene un 69.02% de similitud\n",
      "            - Bank tiene un 66.99% de similitud\n",
      "    - (vegetation|NOUN):\n",
      "         - Sense2Vec:\n",
      "            - plant_life siendo un NOUN tiene un 90.17% de similitud\n",
      "            - grasses siendo un NOUN tiene un 87.39% de similitud\n",
      "            - foliage siendo un NOUN tiene un 85.72% de similitud\n",
      "         - Word2Vec:\n",
      "            - grasses tiene un 74.98% de similitud\n",
      "            - woody_vegetation tiene un 72.40% de similitud\n",
      "            - Vegetation tiene un 70.62% de similitud\n"
     ]
    }
   ],
   "source": [
    "sents = [\n",
    "    \"I went to the bank to deposit my money.\",\n",
    "    \"The land along the river bank has vegetation.\"\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tok_tagged_sents = [[(token.lower_, token.pos_) for token in nlp(s) if (token.is_alpha and (not token.is_stop))] for s in sents]\n",
    "\n",
    "print(f\"- Sentencias tokenizadas y etiquetadas (POS tagged):\\n{tok_tagged_sents}\")\n",
    "\n",
    "print(\"- 3 palabras más similares de...\")\n",
    "for s in tok_tagged_sents:\n",
    "    for word, pos_tag in s:\n",
    "        print(f\"    - ({word}|{pos_tag}):\")\n",
    "        print(\"         - Sense2Vec:\")\n",
    "        three_most_similar = s2v.most_similar(\"|\".join([word, pos_tag]), n=3)\n",
    "        for ms in three_most_similar:\n",
    "            w = ms[0].split(\"|\")[0]\n",
    "            pt = ms[0].split(\"|\")[1]\n",
    "            sim = ms[1]\n",
    "            print(f\"            - {w} siendo un {pt} tiene un {sim*100:.2f}% de similitud\")\n",
    "        \n",
    "        print(\"         - Word2Vec:\")\n",
    "        three_most_similar = w2v.most_similar(word, topn=3)\n",
    "        for ms in three_most_similar:\n",
    "            w = ms[0]\n",
    "            sim = ms[1]\n",
    "            print(f\"            - {w} tiene un {sim*100:.2f}% de similitud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud utilizando S2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Similitud entre watch (noun) y watch (verb): 0.479771226644516\n",
      "- Similitud entre watch (noun) y clock (noun): 0.5055921077728271\n",
      "- Similitud entre watch (noun) y view (verb): 0.3805285096168518\n",
      "- Similitud entre watch (verb) y clock (noun): 0.3295963704586029\n",
      "- Similitud entre watch (verb) y view (verb): 0.4352375566959381\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Similitud entre watch (noun) y watch (verb): {s2v.similarity(\"watch|NOUN\", \"watch|VERB\")}\")\n",
    "print(f\"- Similitud entre watch (noun) y clock (noun): {s2v.similarity(\"watch|NOUN\", \"clock|NOUN\")}\")\n",
    "print(f\"- Similitud entre watch (noun) y view (verb): {s2v.similarity(\"watch|NOUN\", \"view|VERB\")}\")\n",
    "print(f\"- Similitud entre watch (verb) y clock (noun): {s2v.similarity(\"watch|VERB\", \"clock|NOUN\")}\")\n",
    "print(f\"- Similitud entre watch (verb) y view (verb): {s2v.similarity(\"watch|VERB\", \"view|VERB\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 2\n",
    "- Los modelos de embedding estáticos anteriormente vistos (Word2Vec, GloVe, FastText y Sense2Vec) generan representaciones a nivel palabra. Sin embargo, a la hora de llevar a cabo diferentes tareas de PLN, podría ser interesante obtener una representación a nivel documento que sea capaz de capturar la semántica global del mismo.\n",
    "\n",
    "- En este contexto surge Doc2Vec, extensión de Wor2Vec diseñada para representar textos de forma integral. A diferencia de los anteriores modelos pre-entrenados que únicamente generan embeddings a nivel de token, Doc2Vec introduce un vector que representa al documento en su totalidad. Con dicho fin, hace uso de, o bien la técnica Distributed Memory (PV-DM), análoga a CBOW, o bien de la técnica Distributed Bag of Words (PV-DBOW), análoga a Skip-Gram. Específicamente, PV-DM predice una palabra en función de su contexto y del vector del documento, mientras que PV-DBOW omite el contexto y utiliza exclusivamente el vector para predecir las palabras que lo conforman.\n",
    "\n",
    "- Se pide:\n",
    "    - Preparar conjunto aleatorio de 10000 resúmenes de Wikipedia en inglés.\n",
    "    - Utiliza TaggedDocument de la librería Gensim para representar el dataset de entrenamiento. Tras ello, entrena un modelo Doc2Vec sobre el anterior conjunto de datos.\n",
    "    - Dados los resúmenes de Wikipedia de \"Federico García Lorca\", \"Flag of Europe\" y \"Super Mario 64\", calcula para cada uno sus 10 resúmenes más similares. Analiza los resultados. ¿Están relacionados?\n",
    "    - Dado un nuevo resumen no visto durante el entrenamiento, calcula su vector y analiza los resúmenes más similares al mismo.\n",
    "    - Representa gráficamente con PCA y la librería Bokeh un subconjunto de los anteriores resúmenes de Wikipedia.\n",
    "    - Sobre los apartados anteriores, experimenta con diferentes configuraciones de entrenamiento de Doc2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener conjunto de resúmenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"laion/Wikipedia-Abstract\", \"English\")\n",
    "subset = dataset[\"train\"].select(range(10000))\n",
    "texts, titles = subset[\"Abstract\"], subset[\"Title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar conjunto de resúmenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(model, text):\n",
    "    doc = model(text)\n",
    "    return [token.lower_ for token in doc if ((not token.is_stop) and token.is_alpha)]\n",
    "\n",
    "# Aplicar pre-procesamiento a todos los textos del corpus\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "preprocessed_texts = [preprocess_text(nlp, s) for s in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los `TaggedDocument`s y entrenar el modelo D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_documents = [TaggedDocument(words=preprocessed_texts[i], tags=[titles[i]]) for i in range(len(preprocessed_texts))]\n",
    "d2v = Doc2Vec(tagged_documents, vector_size=100, window=2, min_count=1, workers=4, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener 10 resúmenes más similares de..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 6575217/6575217 [00:42<00:00, 155810.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "filtered = dataset[\"train\"].filter(lambda x: x[\"Title\"] == \"Flag of Europe\" or x[\"Title\"] == \"Federico García Lorca\" or x[\"Title\"] == \"Super Mario 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preprocessed = [(t, preprocess_text(nlp, s)) for s, t in zip(filtered[\"Abstract\"], filtered[\"Title\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Top 10 resúmenes más similares a...\n",
      "    - Federico García Lorca:\n",
      "        - Federico García Lorca tiene un 96.60% de similitud\n",
      "        - Jorge Aragão tiene un 96.36% de similitud\n",
      "        - Guy of Bazoches tiene un 96.36% de similitud\n",
      "        - Myrta Silva tiene un 96.28% de similitud\n",
      "        - Georges Courteline tiene un 96.20% de similitud\n",
      "        - Jean Mabillon tiene un 96.20% de similitud\n",
      "        - Bita Farrahi tiene un 96.12% de similitud\n",
      "        - Philippe Goddin tiene un 95.97% de similitud\n",
      "        - Allegra Versace tiene un 95.97% de similitud\n",
      "        - El Cid tiene un 95.96% de similitud\n",
      "    - Super Mario 64:\n",
      "        - Super Mario 64 tiene un 96.07% de similitud\n",
      "        - Super Mario Land 2: 6 Golden Coins tiene un 95.66% de similitud\n",
      "        - The Time Warp of Dr. Brain tiene un 93.21% de similitud\n",
      "        - Music of the Final Fantasy series tiene un 92.21% de similitud\n",
      "        - List of campaign settings tiene un 91.58% de similitud\n",
      "        - Irregular chess opening tiene un 90.93% de similitud\n",
      "        - Dr. Brain tiene un 90.70% de similitud\n",
      "        - Transformers: The Game tiene un 90.00% de similitud\n",
      "        - Wario tiene un 89.74% de similitud\n",
      "        - Play-by-post role-playing game tiene un 89.54% de similitud\n",
      "    - Flag of Europe:\n",
      "        - Flag of Europe tiene un 95.84% de similitud\n",
      "        - Member states of the World Trade Organization tiene un 92.17% de similitud\n",
      "        - Euroscepticism tiene un 91.74% de similitud\n",
      "        - Master of the Horse tiene un 90.74% de similitud\n",
      "        - Great Britain at the 2004 Summer Paralympics tiene un 90.57% de similitud\n",
      "        - Azerbaijan national rugby union team tiene un 90.30% de similitud\n",
      "        - USS Bancroft (1892) tiene un 89.40% de similitud\n",
      "        - List of galleons of Spain tiene un 89.34% de similitud\n",
      "        - Nothing about us without us tiene un 89.17% de similitud\n",
      "        - Holodomor tiene un 89.03% de similitud\n"
     ]
    }
   ],
   "source": [
    "print(\"- Top 10 resúmenes más similares a...\")\n",
    "for title, text in filtered_preprocessed:\n",
    "    print(f\"    - {title}:\")\n",
    "    inferred_vector = d2v.infer_vector(text)\n",
    "    most_similar = d2v.dv.most_similar([inferred_vector], topn=10)\n",
    "    for ms in most_similar:\n",
    "        print(f\"        - {ms[0]} tiene un {ms[1]*100:.2f}% de similitud\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
