{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "english_sw = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 1\n",
    "- Se quiere crear una matriz de coocurrencias para el siguiente párrafo:  \n",
    "    “Mysterious tunnels sketched by Leonardo da Vinci in the late 1400s may have been found at the Castle. Secret tunnels at the Sforza Castle.”  \n",
    "\n",
    "    Los pasos que hay que seguir para hacer esto podrían ser los siguientes:\n",
    "    - Preprocesar el texto eliminando stopwords, convirtiendo las palabras a\n",
    "    minúsculas, tokenizando y eliminando los tokens no alfanuméricos.\n",
    "    - Generar el vocabulario (palabras únicas en el texto, sin repeticiones).\n",
    "    - Decidir el tamaño de ventana del contexto y buscar todos los pares de palabras que coocurren dentro de ese tamaño de ventana, contando las veces que coaparecen.  \n",
    "    **Para este ejercicio poner un tamaño de ventana para el contexto = 2.**\n",
    "    - Crear la matriz de coocurrencias utilizando las frecuencias calculadas antes.\n",
    "    - Visualizar la matriz utilizando DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    word_tokenized = regexp_tokenize(text, r\"[a-zA-Z0-9]+\")\n",
    "    word_tokenized = [w.lower() for w in word_tokenized if w.lower() not in english_sw]\n",
    "    return word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mysterious', 'tunnels', 'sketched', 'leonardo', 'da', 'vinci', 'late', '1400s', 'may', 'found', 'castle', 'secret', 'tunnels', 'sforza', 'castle']\n"
     ]
    }
   ],
   "source": [
    "text = \"Mysterious tunnels sketched by Leonardo da Vinci in the late 1400s may have been found at the Castle. Secret tunnels at the Sforza Castle.\"\n",
    "# Aplicar el preprocesamiento al texto dado\n",
    "preprocessed_text = text_preprocessing(text)\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Generar vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'found', 'tunnels', 'sforza', 'late', '1400s', 'may', 'mysterious', 'da', 'vinci', 'castle', 'sketched', 'secret', 'leonardo'}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(preprocessed_text)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Decidir ventana del contexto y obtener pares de palabras que co-ocurren en ella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'collections.Counter'>, {'mysterious': Counter({'tunnels': 1, 'sketched': 1}), 'tunnels': Counter({'castle': 2, 'mysterious': 1, 'sketched': 1, 'leonardo': 1, 'secret': 1, 'sforza': 1}), 'sketched': Counter({'mysterious': 1, 'tunnels': 1, 'leonardo': 1, 'da': 1}), 'leonardo': Counter({'tunnels': 1, 'sketched': 1, 'da': 1, 'vinci': 1}), 'da': Counter({'sketched': 1, 'leonardo': 1, 'vinci': 1, 'late': 1}), 'vinci': Counter({'leonardo': 1, 'da': 1, 'late': 1, '1400s': 1}), 'late': Counter({'da': 1, 'vinci': 1, '1400s': 1, 'may': 1}), '1400s': Counter({'vinci': 1, 'late': 1, 'may': 1, 'found': 1}), 'may': Counter({'late': 1, '1400s': 1, 'found': 1, 'castle': 1}), 'found': Counter({'1400s': 1, 'may': 1, 'castle': 1, 'secret': 1}), 'castle': Counter({'tunnels': 2, 'may': 1, 'found': 1, 'secret': 1, 'sforza': 1}), 'secret': Counter({'found': 1, 'castle': 1, 'tunnels': 1, 'sforza': 1}), 'sforza': Counter({'secret': 1, 'tunnels': 1, 'castle': 1})})\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "co_occurrences = defaultdict(Counter)\n",
    "for i, word in enumerate(preprocessed_text):\n",
    "    for j in range(max(0, i-window_size), min(len(preprocessed_text), i + window_size + 1)):\n",
    "        if i != j:\n",
    "            co_occurrences[word][preprocessed_text[j]] += 1\n",
    "\n",
    "print(co_occurrences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
