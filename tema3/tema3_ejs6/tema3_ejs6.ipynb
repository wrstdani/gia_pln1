{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "spanish_sw = set(stopwords.words(\"spanish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 1\n",
    "- La recuperación de información es el proceso de búsqueda, extracción y recomendación de documentos relevantes dentro de un amplio conjunto de datos en función de una consulta específica. Este procedimiento es de vital importancia en aplicaciones como los motores de búsqueda, los sistemas de recomendación y el análisis de texto en general.\n",
    "\n",
    "- Dado que los documentos suelen estar compuestos por datos no estructurados y, en particular, por texto en lenguaje natural, es necesario en primer lugar transformarlos en una representación computable. Con dicho fin, se pueden utilizar las técnicas de vectorización tradicionales basadas en bolsas de palabras vistas en ejercicios anteriores, las cuales convierten los textos en vectores dispersos dentro de un espacio numérico. A partir de estas representaciones vectoriales de documentos, es posible comparar documentos mediante el empleo de métricas y similitudes como la del coseno, facilitando la identificación de los documentos más relevantes en función de una consulta concreta.\n",
    "\n",
    "- Seguir los siguientes pasos:\n",
    "    - Descargar el fichero `train.xlsx` del conjunto de datos \"The Spanish Fake News Corpus\". Puedes obtener el fichero a través del siguiente link: https://github.com/jpposadas/FakeNewsCorpusSpanish/tree/master\n",
    "    - Vectoriza la columna “Headline” con diferentes preprocesamientos (lematización, filtrado por nombres, adjetivos y verbos, etc), así como vectorizaciones basadas en bolsas de palabras (como matriz TF-IDF).\n",
    "    - Calcula la matriz de similitud coseno de los documentos anteriores. Para el segundo documento (índice 1), obtén sus 4 documentos más similares en función de dicha similitud (5 en total si consideramos al propio documento de consulta). Analiza los resultados. ¿Qué documentos son más similares? ¿Qué grado de similitud tienen los distintos documentos? ¿A qué se debe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Education</td>\n",
       "      <td>El Ruinaversal</td>\n",
       "      <td>RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...</td>\n",
       "      <td>RAE INCLUIRÁ LA PALABRA \"LADY\" EN EL DICCIONAR...</td>\n",
       "      <td>http://www.elruinaversal.com/2017/06/10/rae-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Education</td>\n",
       "      <td>Hay noticia</td>\n",
       "      <td>La palabra \"haiga\", aceptada por la RAE</td>\n",
       "      <td>La palabra \"haiga\", aceptada por la RAE La Rea...</td>\n",
       "      <td>https://haynoticia.es/la-palabra-haiga-aceptad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Education</td>\n",
       "      <td>El Ruinaversal</td>\n",
       "      <td>YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...</td>\n",
       "      <td>YORDI ROSADO ESCRIBIRÁ Y DISEÑARÁ LOS NUEVOS L...</td>\n",
       "      <td>http://www.elruinaversal.com/2018/05/06/yordi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>Education</td>\n",
       "      <td>EL UNIVERSAL</td>\n",
       "      <td>UNAM capacitará a maestros para aprobar prueba...</td>\n",
       "      <td>UNAM capacitará a maestros para aprobar prueba...</td>\n",
       "      <td>http://www.eluniversal.com.mx/articulo/nacion/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Education</td>\n",
       "      <td>Lamula</td>\n",
       "      <td>pretenden aprobar libros escolares con conteni...</td>\n",
       "      <td>Alerta: pretenden aprobar libros escolares con...</td>\n",
       "      <td>https://redaccion.lamula.pe/2018/06/19/memoria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ...                                               Link\n",
       "0   1  ...  http://www.elruinaversal.com/2017/06/10/rae-in...\n",
       "1   2  ...  https://haynoticia.es/la-palabra-haiga-aceptad...\n",
       "2   3  ...  http://www.elruinaversal.com/2018/05/06/yordi-...\n",
       "3   4  ...  http://www.eluniversal.com.mx/articulo/nacion/...\n",
       "4   5  ...  https://redaccion.lamula.pe/2018/06/19/memoria...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar train.xlsx en un DataFrame\n",
    "train = pd.read_excel(\"data/train.xlsx\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar la columna \"Headline\"\n",
    "def preprocess_text(text):\n",
    "    word_tokenized = regexp_tokenize(text, r\"\\w+\")\n",
    "    tagged = nltk.pos_tag(word_tokenized, lang=\"es\")\n",
    "    lemmatized = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
